import customtkinter as ctk
import threading
import tkinter as tk
import os
from tkinter import filedialog
from mediapipe.tasks import python
from mediapipe.tasks.python import gen_ai
import time

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¸Ø§Ù‡Ø±ÛŒ
ctk.set_appearance_mode("Dark")
ctk.set_default_color_theme("dark-blue")

class GemmaMultimodalApp(ctk.CTk):
    def __init__(self):
        super().__init__()

        self.title("Google AI Edge - Gemma Multimodal Interface")
        self.geometry("1000x700")
        
        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„ Ùˆ Ú†Øª
        self.llm_inference = None
        self.model_path = ""
        self.attached_file = None # Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ú†Ø³Ø¨Ø§Ù†Ø¯Ù‡ Ø´Ø¯Ù‡

        # Ø³Ø§Ø®ØªØ§Ø± Ú¯Ø±ÛŒØ¯ Ø§ØµÙ„ÛŒ
        self.grid_columnconfigure(1, weight=1) # Ø³ØªÙˆÙ† Ú†Øª Ù¾Ù‡Ù†â€ŒØªØ± Ø¨Ø§Ø´Ø¯
        self.grid_rowconfigure(0, weight=1)

        # --- 1. Ù¾Ù†Ù„ Ø³Ù…Øª Ú†Ù¾ (ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§) ---
        self.sidebar_frame = ctk.CTkFrame(self, width=200, corner_radius=0)
        self.sidebar_frame.grid(row=0, column=0, sticky="nsew", padx=5, pady=5)
        
        self.logo_label = ctk.CTkLabel(self.sidebar_frame, text="AI Edge Studio", font=ctk.CTkFont(size=20, weight="bold"))
        self.logo_label.pack(pady=20)

        self.btn_load = ctk.CTkButton(self.sidebar_frame, text="Load LLM (.task)", command=self.load_model_dialog)
        self.btn_load.pack(pady=10, padx=10)
        
        self.lbl_status = ctk.CTkLabel(self.sidebar_frame, text="No Model", text_color="orange", wraplength=180)
        self.lbl_status.pack(pady=5)

        ctk.CTkLabel(self.sidebar_frame, text="Multimodal Input:", font=ctk.CTkFont(weight="bold")).pack(pady=(20, 5))
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÙˆØ³Øª ÙØ§ÛŒÙ„
        self.btn_attach_img = ctk.CTkButton(self.sidebar_frame, text="Attach Image", fg_color="#2c3e50", command=lambda: self.attach_file("image"))
        self.btn_attach_img.pack(pady=5, padx=10)
        
        self.btn_attach_audio = ctk.CTkButton(self.sidebar_frame, text="Attach Audio", fg_color="#2c3e50", command=lambda: self.attach_file("audio"))
        self.btn_attach_audio.pack(pady=5, padx=10)

        self.lbl_file_attached = ctk.CTkLabel(self.sidebar_frame, text="No file attached", text_color="gray", wraplength=180)
        self.lbl_file_attached.pack(pady=10)

        # --- 2. Ø¨Ø®Ø´ Ø§ØµÙ„ÛŒ Ú†Øª (Ø³Ù…Øª Ø±Ø§Ø³Øª) ---
        self.chat_frame = ctk.CTkFrame(self, fg_color="transparent")
        self.chat_frame.grid(row=0, column=1, sticky="nsew", padx=10, pady=10)
        self.chat_frame.grid_rowconfigure(0, weight=1)
        self.chat_frame.grid_columnconfigure(0, weight=1)

        # Ù†Ù…Ø§ÛŒØ´Ú¯Ø± Ú†Øª
        self.chat_display = ctk.CTkTextbox(self.chat_frame, state="disabled", wrap="word", font=ctk.CTkFont(size=13))
        self.chat_display.grid(row=0, column=0, sticky="nsew", pady=(0, 10))
        
        # ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ø±Ù†Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ùˆ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
        self.chat_display.tag_config("user_tag", foreground="#3498db")
        self.chat_display.tag_config("ai_tag", foreground="#2ecc71")
        self.chat_display.tag_config("file_tag", foreground="#e67e22", font=ctk.CTkFont(slant="italic"))

        # --- 3. Ø¨Ø®Ø´ ÙˆØ±ÙˆØ¯ÛŒ (Ù¾Ø§ÛŒÛŒÙ†) ---
        self.input_area = ctk.CTkFrame(self.chat_frame, fg_color="transparent")
        self.input_area.grid(row=1, column=0, sticky="ew")
        self.input_area.grid_columnconfigure(0, weight=1)

        self.entry_msg = ctk.CTkEntry(self.input_area, placeholder_text="Ask Gemma anything... (use attached files placeholder)")
        self.entry_msg.grid(row=0, column=0, sticky="ew", padx=(0, 10))
        self.entry_msg.bind("<Return>", self.start_generation)

        self.btn_send = ctk.CTkButton(self.input_area, text="Send", width=100, command=self.start_generation)
        self.btn_send.grid(row=0, column=1)

    # --- ØªÙˆØ§Ø¨Ø¹ Ù…Ø¯Ù„ ---

    def load_model_dialog(self):
        file_path = filedialog.askopenfilename(filetypes=[("MediaPipe Task", "*.task")])
        if file_path:
            self.model_path = file_path
            self.lbl_status.configure(text="Loading...", text_color="yellow")
            # Ø§Ø¬Ø±Ø§ Ø¯Ø± ØªØ±Ø¯ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
            threading.Thread(target=self.init_mediapipe, daemon=True).start()

    def init_mediapipe(self):
        try:
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§ÛŒÙ‡ Ù…Ø¯Ù„
            base_options = python.BaseOptions(model_asset_path=self.model_path)
            
            # ØªØ¹Ø±ÛŒÙ Ú©ÙˆÙ„â€ŒØ¨Ú© Ø¨Ø±Ø§ÛŒ Streaming
            def progress_callback(output_text, done):
                # Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ÙˆÙ‚ØªÛŒ Ù‡Ø± ØªÚ©Ù‡ Ù…ØªÙ† ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                self.update_ai_response_stream(output_text, done)

            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Streaming
            options = gen_ai.LlmInferenceOptions(
                base_options=base_options,
                result_callback=progress_callback # ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø§Ø³ØªØ±ÛŒÙ…
            )
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ø§ÛŒÙ†ÙØ±Ù†Ø³ (Ø¨ØµÙˆØ±Øª Async Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ±ÛŒÙ…)
            self.llm_inference = gen_ai.LlmInference.create_from_options(options)
            
            model_name = os.path.basename(self.model_path)
            self.lbl_status.configure(text=f"Active: {model_name}", text_color="green")
        except Exception as e:
            self.lbl_status.configure(text=f"Error: {str(e)}", text_color="red")

    # --- ØªÙˆØ§Ø¨Ø¹ Ù…Ø§Ù„ØªÛŒâ€ŒÙ…Ø¯ÛŒØ§ ---

    def attach_file(self, file_type):
        file_types_map = {
            "image": [("Images", "*.png;*.jpg;*.jpeg")],
            "audio": [("Audio", "*.mp3;*.wav;*.ogg")]
        }
        file_path = filedialog.askopenfilename(filetypes=file_types_map[file_type])
        if file_path:
            self.attached_file = {"path": file_path, "type": file_type}
            file_name = os.path.basename(file_path)
            self.lbl_file_attached.configure(text=f"Attached {file_type}: {file_name}", text_color="#e67e22")
            # Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… Ú©Ù‡ Ø¯Ø± Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ù‡ ÙØ§ÛŒÙ„ Ø§Ø´Ø§Ø±Ù‡ Ú©Ù†Ø¯
            current_text = self.entry_msg.get()
            if "[file]" not in current_text:
                 self.entry_msg.insert(0, f"Based on this {file_type} [file], ")

    # --- ØªÙˆØ§Ø¨Ø¹ Ú†Øª Ùˆ Ø§Ø³ØªØ±ÛŒÙ…ÛŒÙ†Ú¯ ---

    def append_text(self, text, tag=None, markdown=False):
        self.chat_display.configure(state="normal")
        self.chat_display.insert("end", text, tag)
        self.chat_display.configure(state="disabled")
        self.chat_display.see("end")

    def start_generation(self, event=None):
        if not self.llm_inference:
            tk.messagebox.showwarning("Model Not Loaded", "Please load a Gemma .task model first.")
            return
        
        user_input = self.entry_msg.get()
        if not user_input and not self.attached_file:
            return

        # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        self.append_text("\nğŸ‘¤ You: ", "user_tag")
        
        final_prompt = user_input
        
        # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ÛŒ Ù¾ÛŒÙˆØ³Øª Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ø¯Ø± Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… (Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆØ§Ù‚Ø¹ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ø¯Ù„ Ù…Ø§Ù„ØªÛŒâ€ŒÙ…Ø¯ÛŒØ§ Ø¯Ø§Ø±Ø¯)
        if self.attached_file:
            file_name = os.path.basename(self.attached_file['path'])
            self.append_text(f"[Attached {self.attached_file['type']}: {file_name}] ", "file_tag")
            # Ø¯Ø± Ù†Ø³Ø®Ù‡ ÙØ¹Ù„ÛŒØŒ Ù…Ø§ ÙÙ‚Ø· Ù…ØªÙ†ÛŒ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…. Ù¾Ø±Ø§Ù…Ù¾Øª Ø±Ø§ Ú©Ù…ÛŒ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
            if "[file]" in user_input:
                 final_prompt = user_input.replace("[file]", f"(user attached a {self.attached_file['type']} named {file_name})")
        
        self.append_text(user_input + "\n")
        self.entry_msg.delete(0, "end")
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® AI
        self.append_text("ğŸ¤– Gemma: ", "ai_tag")
        self.current_ai_response_start_index = self.chat_display.index("end-1c")
        
        # ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø¯Ú©Ù…Ù‡ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø± Ø­ÛŒÙ† ØªÙˆÙ„ÛŒØ¯
        self.btn_send.configure(state="disabled")
        
        # **Ø§Ø¬Ø±Ø§ÛŒ Async** (Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ÙÙˆØ±Ø§Ù‹ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯ØŒ Ù†ØªÛŒØ¬Ù‡ Ø§Ø² Ø·Ø±ÛŒÙ‚ Callback Ù…ÛŒâ€ŒØ¢ÛŒØ¯)
        try:
            self.llm_inference.generate_async(final_prompt)
        except Exception as e:
            self.append_text(f"\nError: {str(e)}")
            self.btn_send.configure(state="normal")

    def update_ai_response_stream(self, output_text, done):
        # Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ØªÙˆØ³Ø· ØªØ±Ø¯ Ù…Ø¯ÛŒØ§Ù¾Ø§ÛŒÙ¾ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ø¨Ø§ÛŒØ¯ ØªØºÛŒÛŒØ±Ø§Øª UI Ø±Ø§ Ø¨Ù‡ ØªØ±Ø¯ Ø§ØµÙ„ÛŒ Ø¨ÙØ±Ø³ØªÛŒÙ…
        self.after(0, lambda: self._safe_update_ui(output_text, done))

    def _safe_update_ui(self, output_text, done):
        # Ø§ÙØ²ÙˆØ¯Ù† ØªÚ©Ù‡ Ù…ØªÙ† Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ Ø§Ø¯ÛŒØªÙˆØ±
        self.chat_display.configure(state="normal")
        self.chat_display.insert("end", output_text)
        self.chat_display.configure(state="disabled")
        self.chat_display.see("end")
        
        if done:
            # Ù¾Ø§ÛŒØ§Ù† ØªÙˆÙ„ÛŒØ¯
            self.append_text("\n")
            self.btn_send.configure(state="normal")
            # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ù¾ÛŒÙˆØ³Øª Ø´Ø¯Ù‡ Ù¾Ø³ Ø§Ø² Ø§Ø±Ø³Ø§Ù„
            self.attached_file = None
            self.lbl_file_attached.configure(text="No file attached", text_color="gray")

if __name__ == "__main__":
    app = GemmaMultimodalApp()
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢ÛŒÚ©ÙˆÙ† Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    # if os.path.exists("icon.ico"): app.iconbitmap("icon.ico")
    app.mainloop()
